# -*- coding: utf-8 -*-
"""Lab 4 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KWHaILSFtfrTaCbFI_sRjgGBWt4pcs1y
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df=pd.read_csv("/content/drive/MyDrive/male_players (legacy).csv", na_values='-')
df

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split, cross_val_score
#from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import pickle as pkl

pip install xgboost

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import pickle as pkl

def preprocessing(data):
  data.drop(['ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ls','st','rs','lw','lf','cf','rf'], axis=1,inplace=True)
  categorical_features = data.select_dtypes(include=['object'])
  data.drop(categorical_features, axis=1, inplace=True)
  data.drop(['movement_acceleration', 'movement_sprint_speed',
        'movement_agility', 'movement_reactions', 'movement_balance',
        'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',
        'power_long_shots', 'mentality_aggression', 'mentality_interceptions',
        'mentality_positioning', 'mentality_vision', 'mentality_penalties',
        'mentality_composure', 'defending_marking_awareness',
        'defending_standing_tackle', 'defending_sliding_tackle',
        'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',
        'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed'], axis=1, inplace=True)
  imputer=IterativeImputer(max_iter=10,random_state=0)
  data=pd.DataFrame(np.round(imputer.fit_transform(data)),columns=data.columns)
  return data

def feature_engineering(df):
    #Defining the features and target variables
    X= df.drop(columns=['overall'])
    y=df['overall']

    # Initialize SelectKBest with the desired number of features and the scoring function
    k = 10  # Number of top features to select from the dataset
    selector = SelectKBest(score_func=f_regression, k=k)


    # Fit the selector to the data
    X_new = selector.fit_transform(X, y)

    # Create a dictionary to store the selcted features
    selected_feature_names = X.columns[selector.get_support()]
    selected_feature_names
    selected_df = pd.DataFrame(X_new, columns=selected_features)

    selected_df = {}

    for column in selected_df.columns:
      max_value = selected_df[column].max()
      min_value = selected_df[column].min()
      selected_df[column] = {
          'max_value': max_value,
          'min_value': min_value,}
    pkl.dump(selected_features, open('/content/selected_features.pkl', 'wb'))
    # Separate features and target variable
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_new)
    return (X_scaled,y)

pre_data = preprocessing(df)
selected_data = feature_engineering(pre_data)

def training_testing(X,Y):

    #Split the data into training and testing sets
    X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size = 0.2, random_state = 42)

    # Initialize models
    rf_model = RandomForestRegressor(random_state=42)
    xgb_model = XGBRegressor(random_state=42)
    gb_model = GradientBoostingRegressor(random_state=42)

    #Trianing the three models
    for model in (rf_model, xgb_model,gb_model):
        model.fit(X_train,y_train)
        pkl.dump(model, open('/content/' + model.__class__.__name__ + '.pkl', 'wb'))
        y_pred = model.predict(X_test)
        print(model.__class__.__name__, np.sqrt(mean_squared_error(y_test, y_pred)), mean_absolute_error(y_test, y_pred))
    return  X_train,X_test,y_train,y_test

pre_data = preprocessing(df)
selected_data = feature_engineering(pre_data)
tested_data = training_testing(selected_data[0],selected_data[1])

import pandas as pd
from sklearn.model_selection import GridSearchCV

# Define models and their parameter grids
models = [
    (RandomForestRegressor(random_state=42),
     {
         'n_estimators': [10,100],
         'max_depth': [10,20],
         'min_samples_split': [20, 50]
     }),

    (XGBRegressor(random_state=42),
     {
         'n_estimators': [20,50],
         'max_depth': [20,50],
         'learning_rate': [0.01, 0.001]
     }),

    (GradientBoostingRegressor(random_state=42),
     {
         'n_estimators': [20,50],
         'max_depth': [20,50],
         'learning_rate': [0.01, 0.001]
     })
]

# Perform GridSearchCV for each model
results = []
for model, param_grid in models:
    print(f"Running GridSearchCV for {model.__class__.__name__}...")
    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)
    grid_search.fit(tested_data[0], tested_data[2])
    results.append({
        'model_name': model.__class__.__name__,
        'best_params': grid_search.best_params_,
        'best_rmse': np.sqrt(-grid_search.best_score_)
    })

for result in results:
    print(f"\n{result['model_name']} - Best parameters found:", result['best_params'])
    print(f"{result['model_name']} - Best RMSE score found:", result['best_rmse'])

for model, result in zip(models, results):
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(tested_data[1])
    rmse = np.sqrt(mean_squared_error(tested_data[3], y_pred))
    print(f"\n{model[0].__class__.__name__} - RMSE on test set:", rmse)
pkl.dump(best_model, open('/content/' + model[0].__class__.__name__ + '.pkl', 'wb'))

player_22 =pd.read_csv("/content/drive/MyDrive/players_22.csv", na_values='-')
players_processed = preprocessing(player_22)
# Extract features and actual values from player_features
player_features =feature_engineering(players_processed)
X_new = player_features[0]
real_values = player_features[1]

# Make predictions on the new data
predicted_values = best_model.predict(X_new)

import joblib

# Load your trained model (assuming it was saved after training)
model = joblib.load('/content/XGBRegressor.pkl')
# Calculate evaluation metrics
mean_absolute_error = mean_absolute_error(real_values, predicted_values)
root_mean_squared_error = np.sqrt(mean_squared_error(real_values, predicted_values))

# Print evaluation metrics
print(f"\nMean Absolute Error (Mean_Absolute_Error): {mean_absolute_error},Root Mean Squared Error (Root_Mean_Squared_Error): {root_mean_squared_error}")

# Create a DataFrame for comparison
comparison_dataframe = pd.DataFrame({'Real Values': real_values,'Predicted Values': predicted_values})

print(f"Prediction Comparison DataFrame:{comparison_dataframe}")

Final_best_model = grid_search.best_estimator_

import joblib
joblib.dump(Final_best_model,'model.pkl')